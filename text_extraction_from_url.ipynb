{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textstat\n",
      "  Downloading textstat-0.7.3-py3-none-any.whl (105 kB)\n",
      "     ------------------------------------ 105.1/105.1 KB 870.4 kB/s eta 0:00:00\n",
      "Collecting pyphen\n",
      "  Downloading pyphen-0.12.0-py3-none-any.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: pyphen, textstat\n",
      "Successfully installed pyphen-0.12.0 textstat-0.7.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\ayada\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "! pip install textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Neccesary Library\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from textstat.textstat import textstatistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df=pd.read_excel(r'D:\\20211030 Test Assignment\\Input.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://insights.blackcoffer.com/is-telehealth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://insights.blackcoffer.com/how-telehealt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://insights.blackcoffer.com/is-telemedici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://insights.blackcoffer.com/is-telehealth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://insights.blackcoffer.com/how-people-di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>146</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>147</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>148</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>149</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL\n",
       "0         1  https://insights.blackcoffer.com/is-telehealth...\n",
       "1         2  https://insights.blackcoffer.com/how-telehealt...\n",
       "2         3  https://insights.blackcoffer.com/is-telemedici...\n",
       "3         4  https://insights.blackcoffer.com/is-telehealth...\n",
       "4         5  https://insights.blackcoffer.com/how-people-di...\n",
       "..      ...                                                ...\n",
       "145     146  https://insights.blackcoffer.com/blockchain-fo...\n",
       "146     147  https://insights.blackcoffer.com/the-future-of...\n",
       "147     148  https://insights.blackcoffer.com/big-data-anal...\n",
       "148     149  https://insights.blackcoffer.com/business-anal...\n",
       "149     150  https://insights.blackcoffer.com/challenges-an...\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/60.0\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://insights.blackcoffer.com/impact-of-covid-19-coronavirus-on-the-global-economy/\n"
     ]
    }
   ],
   "source": [
    "url='https://insights.blackcoffer.com/impact-of-covid-19-coronavirus-on-the-global-economy/'\n",
    "print(url)\n",
    "def data_extraction(url):\n",
    "    r=requests.get(url,headers=headers)\n",
    "    content=r.content\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    para_title=soup.title.string\n",
    "    job_elements = str(soup.find_all(\"div\", class_=\"td-post-content\"))\n",
    "    para=job_elements.replace('</p>, <p>','\\n')\n",
    "    cleanr = re.compile(r'<[^>]+>')\n",
    "    para = cleanr.sub('', job_elements)\n",
    "    cleantext=para.strip('[]')\n",
    "    all_data= para_title+\"\\n\"+cleantext\n",
    "    return all_data\n",
    "#print(data_extraction(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WordPress › Error\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=data_extraction(url)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\20211030 Test Assignment\\Extracted text\\httpsinsights.blackcoffer.comhow-does-big-data-help-in-finance-and-the-growth-of-large-firms.txt\n"
     ]
    }
   ],
   "source": [
    "filename=\"\"\n",
    "for i in url:\n",
    "    if i not in '\\:*?\"<>/|':\n",
    "        filename+=i\n",
    "\n",
    "#filepath=r'D:\\20211030 Test Assignment\\Extracted text\\{}.txt'.format(filename)\n",
    "filepath=r'D:\\20211030 Test Assignment\\Extracted text\\httpsinsights.blackcoffer.comhow-does-big-data-help-in-finance-and-the-growth-of-large-firms.txt'\n",
    "print(filepath)\n",
    "with open(filepath,'w', encoding=\"utf-8\") as d:\n",
    "    for i in data:\n",
    "        d.write(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_reader(file_name):\n",
    "    path=r'D:\\20211030 Test Assignment\\Extracted text'\n",
    "    file_path=\"{}\\{}.txt\".format(path,file_name)\n",
    "    with open(file_path,'r', encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_name(url_id):\n",
    "    return str(url_id)\n",
    "url_df['file_name']=url_df[\"URL_ID\"].apply(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df[\"file_data\"]=url_df[\"file_name\"].apply(data_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopword():\n",
    "    path=r'D:\\20211030 Test Assignment\\StopWords'\n",
    "    stop_word=set()\n",
    "    for i in os.listdir(path):\n",
    "        file_path=\"{}\\{}\".format(path,i)\n",
    "        with open(file_path,'r') as f:\n",
    "            for i in f:\n",
    "                i=i.strip('\\n')\n",
    "                a=i.split()\n",
    "                for j in a:\n",
    "                    if j.isalnum():\n",
    "                        stop_word.add(j.lower())\n",
    "    return stop_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word=stopword()\n",
    "\n",
    "def stop_word_removing(data):\n",
    "    data=data.replace('\\n','')\n",
    "    data=data.replace('\\xa0','')\n",
    "    content=\"\"\n",
    "    for word in data:\n",
    "        word=word.lower()\n",
    "        if word not in stop_word:\n",
    "            content+=word\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(text):\n",
    "    text=text.lower()#lowering\n",
    "    words=nltk.tokenize.word_tokenize(text)#tokenization\n",
    "    y=[]\n",
    "    for word in words:\n",
    "        if word.isalnum():#removing special characters\n",
    "            y.append(word)\n",
    "    text=y[:]\n",
    "    y.clear()\n",
    "    for word in text:#removing stowords and punctuation\n",
    "        if word not in stop_word and word not in string.punctuation:\n",
    "            y.append(word)\n",
    "        \n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df[\"file_data\"]=url_df[\"file_name\"].apply(data_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=transform_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words=set()\n",
    "negative_words=set()\n",
    "d=''\n",
    "with open(r'D:\\20211030 Test Assignment\\MasterDictionary\\negative-words.txt','r') as n:\n",
    "    d=n.readlines(0)\n",
    "    for i in d:\n",
    "        i=i.strip('\\n')\n",
    "        negative_words.add(i)\n",
    "    \n",
    "   \n",
    "\n",
    "with open(r'D:\\20211030 Test Assignment\\MasterDictionary\\positive-words.txt','r') as n:\n",
    "    d=n.readlines(0)\n",
    "    for i in d:\n",
    "        i=i.strip('\\n')\n",
    "        positive_words.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dictionary and assined +1 for positive words and -1 for negative words\n",
    "def positive_score_calculator(text):\n",
    "    text=text.lower()#lowering\n",
    "    words=nltk.tokenize.word_tokenize(text)#tokenization\n",
    "    y=[]\n",
    "    for word in words:\n",
    "        if word.isalnum():#removing special characters\n",
    "            y.append(word)\n",
    "    text=y[:]\n",
    "    y.clear()\n",
    "    for word in text:#removing stowords and punctuation\n",
    "        if word not in stop_word and word not in string.punctuation:\n",
    "            y.append(word)\n",
    "        \n",
    "    clean_text= \" \".join(y)\n",
    "\n",
    "\n",
    "    positive_dictionary=dict()\n",
    "    for i in clean_text.split():\n",
    "        if i in positive_words:\n",
    "            #print('positive_words')\n",
    "            positive_dictionary[i]=+1\n",
    "    return sum(positive_dictionary.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_score_calculator(text):\n",
    "    text=text.lower()#lowering\n",
    "    words=nltk.tokenize.word_tokenize(text)#tokenization\n",
    "    y=[]\n",
    "    for word in words:\n",
    "        if word.isalnum():#removing special characters\n",
    "            y.append(word)\n",
    "    text=y[:]\n",
    "    y.clear()\n",
    "    for word in text:#removing stowords and punctuation\n",
    "        if word not in stop_word and word not in string.punctuation:\n",
    "            y.append(word)\n",
    "        \n",
    "    clean_text= \" \".join(y)\n",
    "\n",
    "    negative_dictionary=dict()\n",
    "    for i in clean_text.split():\n",
    "        if i in negative_words:\n",
    "            #print('negative_words')\n",
    "            negative_dictionary[i]=-1\n",
    "    return sum(negative_dictionary.values())*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df['positive_score']=url_df['file_data'].apply(positive_score_calculator)\n",
    "url_df['negative_score']=url_df['file_data'].apply(negative_score_calculator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polarity Score = (Positive Score – Negative Score)/ ((Positive Score + Negative Score) + 0.000001)\n",
    "def polarity_score(positive_score,negative_score):\n",
    "    return (positive_score-negative_score)/((positive_score+negative_score)+0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df['polarity_score']=url_df.apply(lambda x: polarity_score(x['positive_score'], x['negative_score']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subjectivity Score = (Positive Score + Negative Score)/ ((Total Words after cleaning) + 0.000001)\n",
    "def subjectivity_score(positive_score,negative_score,text):\n",
    "    length=len(transform_text(text).split())\n",
    "    return (positive_score+negative_score)/((length)+0.000001)\n",
    "url_df['subjectivity_score']=url_df.apply(lambda x: subjectivity_score(x['positive_score'], x['negative_score'], x['file_data']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_sentence_length(text):\n",
    "    words=nltk.tokenize.word_tokenize(text)\n",
    "    y=[]\n",
    "    for word in words:\n",
    "        if word.isalnum():#removing special characters\n",
    "            y.append(word)\n",
    "    number_of_words=len(y)\n",
    "    number_of_sentences=len(nltk.tokenize.sent_tokenize(text))\n",
    "    average_sentence_length=number_of_words/number_of_sentences\n",
    "    return average_sentence_length\n",
    "url_df['average_sentence_length']=url_df['file_data'].apply(average_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_of_complex_words(text):\n",
    "    raw_words=nltk.tokenize.word_tokenize(text)\n",
    "    clean_word=[]\n",
    "    for word in raw_words:\n",
    "        if word.isalnum():#removing special characters\n",
    "            clean_word.append(word)\n",
    " \n",
    "    # difficult words are those with syllables > 2\n",
    "    # easy_word_set is provide by Textstat as\n",
    "    # a list of common words\n",
    "    diff_words_set = set()\n",
    "     \n",
    "    for word in clean_word:\n",
    "        syllable_count = textstatistics().syllable_count(word)\n",
    "        if word not in stop_word and syllable_count > 2:\n",
    "            diff_words_set.add(word)\n",
    " \n",
    "    return len(diff_words_set)/len(clean_word)\n",
    "url_df['percentage_of_complex_words']=url_df[\"file_data\"].apply(percentage_of_complex_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fog Index = 0.4 * (Average Sentence Length + Percentage of Complex words)\n",
    "def fog_index(average_sentence_length,percentage_of_complex_words):\n",
    "    return 0.4*(average_sentence_length+percentage_of_complex_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df['fog_index']=url_df.apply(lambda x : fog_index(x['average_sentence_length'], x['percentage_of_complex_words']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_number_of_per_sentence(text):\n",
    "    words=nltk.tokenize.word_tokenize(text)\n",
    "    y=[]\n",
    "    for word in words:\n",
    "        if word.isalnum():#removing special characters\n",
    "            y.append(word)\n",
    "    number_of_words=len(y)\n",
    "    number_of_sentences=len(nltk.tokenize.sent_tokenize(text))\n",
    "    average_sentence_length=number_of_words/number_of_sentences\n",
    "    return average_sentence_length\n",
    "url_df['average_number_of_per_sentence']=url_df['file_data'].apply(average_number_of_per_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_word_count(text):\n",
    "    raw_words=nltk.tokenize.word_tokenize(text)\n",
    "    clean_word=[]\n",
    "    for word in raw_words:\n",
    "        if word.isalnum():#removing special characters\n",
    "            clean_word.append(word)\n",
    " \n",
    "    # difficult words are those with syllables > 2\n",
    "    # easy_word_set is provide by Textstat as\n",
    "    # a list of common words\n",
    "    diff_words_set = set()\n",
    "     \n",
    "    for word in clean_word:\n",
    "        syllable_count = textstatistics().syllable_count(word)\n",
    "        if word not in stop_word and syllable_count > 2:\n",
    "            diff_words_set.add(word)\n",
    " \n",
    "    return len(diff_words_set)\n",
    "url_df['complex_word_count']=url_df[\"file_data\"].apply(complex_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(text):\n",
    "    raw_words=nltk.tokenize.word_tokenize(text)\n",
    "    clean_word=[]\n",
    "    for word in raw_words:\n",
    "        if word.isalnum():#removing special characters\n",
    "            clean_word.append(word)\n",
    "\n",
    "    diff_words_set = list()\n",
    "    for word in clean_word:\n",
    "        if word not in stop_word :\n",
    "            diff_words_set.append(word)\n",
    "    \n",
    "    return len(diff_words_set)\n",
    "\n",
    "url_df['word_count']=url_df[\"file_data\"].apply(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllable_count(text):\n",
    "    raw_words=nltk.tokenize.word_tokenize(text)\n",
    "    clean_word=[]\n",
    "    for word in raw_words:\n",
    "        if word.isalnum():#removing special characters\n",
    "            clean_word.append(word)\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "    for word in clean_word:\n",
    "        word = word.lower()\n",
    "        vowels = \"aeiou\"\n",
    "        if word[0] in vowels:\n",
    "            count += 1\n",
    "        for index in range(1, len(word)):\n",
    "            if word[index] in vowels and word[index - 1] not in vowels:\n",
    "                count += 1\n",
    "                if word.endswith(\"es\") or word.endswith(\"ed\"):\n",
    "                    count -= 1\n",
    "        if count == 0:\n",
    "            count += 1\n",
    "    return count\n",
    "url_df['syllable_count']=url_df[\"file_data\"].apply(syllable_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def personal_pronoun(text):\n",
    "    data=text.replace('\\n','')\n",
    "    data=data.replace('\\xa0','')\n",
    "    pronounRegex = re.compile(r'\\b(I|we|my|ours|(?-i:us))\\b',re.I)\n",
    "    pronouns = pronounRegex.findall(data)\n",
    "    return len(pronouns)\n",
    "url_df[\"personal_pronouns\"]=url_df[\"file_data\"].apply(personal_pronoun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_word_length(text):\n",
    "    raw_words=nltk.tokenize.word_tokenize(text)\n",
    "    clean_word=''\n",
    "    number_of_words=0\n",
    "    for word in raw_words:\n",
    "        if word.isalnum():#removing special characters\n",
    "            clean_word+=word+' '\n",
    "            number_of_words+=1\n",
    "    return len(clean_word)/number_of_words\n",
    "\n",
    "url_df[\"average_word_length\"]=url_df[\"file_data\"].apply(average_word_length)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_data</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>subjectivity_score</th>\n",
       "      <th>average_sentence_length</th>\n",
       "      <th>percentage_of_complex_words</th>\n",
       "      <th>fog_index</th>\n",
       "      <th>average_number_of_per_sentence</th>\n",
       "      <th>complex_word_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>syllable_count</th>\n",
       "      <th>personal_pronouns</th>\n",
       "      <th>average_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://insights.blackcoffer.com/is-telehealth...</td>\n",
       "      <td>1</td>\n",
       "      <td>Is telehealth the future of healthcare? - Blac...</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.078788</td>\n",
       "      <td>26.153846</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>10.558009</td>\n",
       "      <td>26.153846</td>\n",
       "      <td>80</td>\n",
       "      <td>360</td>\n",
       "      <td>1147</td>\n",
       "      <td>0</td>\n",
       "      <td>6.423529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://insights.blackcoffer.com/how-telehealt...</td>\n",
       "      <td>2</td>\n",
       "      <td>How Telehealth and Telemedicine helping people...</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.074271</td>\n",
       "      <td>18.092593</td>\n",
       "      <td>0.061412</td>\n",
       "      <td>7.293946</td>\n",
       "      <td>18.092593</td>\n",
       "      <td>60</td>\n",
       "      <td>422</td>\n",
       "      <td>1543</td>\n",
       "      <td>0</td>\n",
       "      <td>5.923234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://insights.blackcoffer.com/is-telemedici...</td>\n",
       "      <td>3</td>\n",
       "      <td>Is telemedicine effective in treating patients...</td>\n",
       "      <td>48</td>\n",
       "      <td>22</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.080925</td>\n",
       "      <td>18.680851</td>\n",
       "      <td>0.133257</td>\n",
       "      <td>7.570974</td>\n",
       "      <td>18.680851</td>\n",
       "      <td>234</td>\n",
       "      <td>917</td>\n",
       "      <td>3188</td>\n",
       "      <td>1</td>\n",
       "      <td>6.552961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://insights.blackcoffer.com/is-telehealth...</td>\n",
       "      <td>4</td>\n",
       "      <td>The Future of Telehealth Services - Blackcoffe...</td>\n",
       "      <td>35</td>\n",
       "      <td>14</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.054144</td>\n",
       "      <td>20.195402</td>\n",
       "      <td>0.118384</td>\n",
       "      <td>8.168998</td>\n",
       "      <td>20.195402</td>\n",
       "      <td>208</td>\n",
       "      <td>962</td>\n",
       "      <td>3097</td>\n",
       "      <td>0</td>\n",
       "      <td>6.653386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://insights.blackcoffer.com/how-people-di...</td>\n",
       "      <td>5</td>\n",
       "      <td>How are people diverted to Telehealth services...</td>\n",
       "      <td>44</td>\n",
       "      <td>26</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.080645</td>\n",
       "      <td>22.530864</td>\n",
       "      <td>0.123836</td>\n",
       "      <td>9.102428</td>\n",
       "      <td>22.530864</td>\n",
       "      <td>226</td>\n",
       "      <td>936</td>\n",
       "      <td>3144</td>\n",
       "      <td>1</td>\n",
       "      <td>6.504110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>146</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "      <td>146</td>\n",
       "      <td>Blockchain for Payments - Blackcoffer Insights...</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.115090</td>\n",
       "      <td>18.102041</td>\n",
       "      <td>0.134160</td>\n",
       "      <td>7.345890</td>\n",
       "      <td>18.102041</td>\n",
       "      <td>119</td>\n",
       "      <td>443</td>\n",
       "      <td>1393</td>\n",
       "      <td>9</td>\n",
       "      <td>6.198422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>147</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "      <td>147</td>\n",
       "      <td>The future of Investing - Blackcoffer Insights...</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.044910</td>\n",
       "      <td>24.209677</td>\n",
       "      <td>0.092605</td>\n",
       "      <td>9.766749</td>\n",
       "      <td>24.209677</td>\n",
       "      <td>139</td>\n",
       "      <td>766</td>\n",
       "      <td>2362</td>\n",
       "      <td>2</td>\n",
       "      <td>6.035310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>148</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "      <td>148</td>\n",
       "      <td>Big Data Analytics in Healthcare - Blackcoffer...</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.173913</td>\n",
       "      <td>0.080844</td>\n",
       "      <td>17.454545</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>7.064457</td>\n",
       "      <td>17.454545</td>\n",
       "      <td>132</td>\n",
       "      <td>617</td>\n",
       "      <td>1910</td>\n",
       "      <td>2</td>\n",
       "      <td>6.060764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>149</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "      <td>149</td>\n",
       "      <td>Business Analytics In The Healthcare Industry ...</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.067935</td>\n",
       "      <td>24.862069</td>\n",
       "      <td>0.159501</td>\n",
       "      <td>10.062442</td>\n",
       "      <td>24.862069</td>\n",
       "      <td>115</td>\n",
       "      <td>394</td>\n",
       "      <td>1268</td>\n",
       "      <td>0</td>\n",
       "      <td>6.669903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "      <td>150</td>\n",
       "      <td>Challenges and Opportunities of Big Data in He...</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>15.893939</td>\n",
       "      <td>0.106768</td>\n",
       "      <td>6.446041</td>\n",
       "      <td>15.893939</td>\n",
       "      <td>112</td>\n",
       "      <td>534</td>\n",
       "      <td>1668</td>\n",
       "      <td>8</td>\n",
       "      <td>6.012393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL file_name  \\\n",
       "0         1  https://insights.blackcoffer.com/is-telehealth...         1   \n",
       "1         2  https://insights.blackcoffer.com/how-telehealt...         2   \n",
       "2         3  https://insights.blackcoffer.com/is-telemedici...         3   \n",
       "3         4  https://insights.blackcoffer.com/is-telehealth...         4   \n",
       "4         5  https://insights.blackcoffer.com/how-people-di...         5   \n",
       "..      ...                                                ...       ...   \n",
       "145     146  https://insights.blackcoffer.com/blockchain-fo...       146   \n",
       "146     147  https://insights.blackcoffer.com/the-future-of...       147   \n",
       "147     148  https://insights.blackcoffer.com/big-data-anal...       148   \n",
       "148     149  https://insights.blackcoffer.com/business-anal...       149   \n",
       "149     150  https://insights.blackcoffer.com/challenges-an...       150   \n",
       "\n",
       "                                             file_data  positive_score  \\\n",
       "0    Is telehealth the future of healthcare? - Blac...              20   \n",
       "1    How Telehealth and Telemedicine helping people...              19   \n",
       "2    Is telemedicine effective in treating patients...              48   \n",
       "3    The Future of Telehealth Services - Blackcoffe...              35   \n",
       "4    How are people diverted to Telehealth services...              44   \n",
       "..                                                 ...             ...   \n",
       "145  Blockchain for Payments - Blackcoffer Insights...              20   \n",
       "146  The future of Investing - Blackcoffer Insights...              20   \n",
       "147  Big Data Analytics in Healthcare - Blackcoffer...              19   \n",
       "148  Business Analytics In The Healthcare Industry ...              21   \n",
       "149  Challenges and Opportunities of Big Data in He...              20   \n",
       "\n",
       "     negative_score  polarity_score  subjectivity_score  \\\n",
       "0                 6        0.538462            0.078788   \n",
       "1                 9        0.357143            0.074271   \n",
       "2                22        0.371429            0.080925   \n",
       "3                14        0.428571            0.054144   \n",
       "4                26        0.257143            0.080645   \n",
       "..              ...             ...                 ...   \n",
       "145              25       -0.111111            0.115090   \n",
       "146              10        0.333333            0.044910   \n",
       "147              27       -0.173913            0.080844   \n",
       "148               4        0.680000            0.067935   \n",
       "149              30       -0.200000            0.102041   \n",
       "\n",
       "     average_sentence_length  percentage_of_complex_words  fog_index  \\\n",
       "0                  26.153846                     0.117647  10.558009   \n",
       "1                  18.092593                     0.061412   7.293946   \n",
       "2                  18.680851                     0.133257   7.570974   \n",
       "3                  20.195402                     0.118384   8.168998   \n",
       "4                  22.530864                     0.123836   9.102428   \n",
       "..                       ...                          ...        ...   \n",
       "145                18.102041                     0.134160   7.345890   \n",
       "146                24.209677                     0.092605   9.766749   \n",
       "147                17.454545                     0.114583   7.064457   \n",
       "148                24.862069                     0.159501  10.062442   \n",
       "149                15.893939                     0.106768   6.446041   \n",
       "\n",
       "     average_number_of_per_sentence  complex_word_count  word_count  \\\n",
       "0                         26.153846                  80         360   \n",
       "1                         18.092593                  60         422   \n",
       "2                         18.680851                 234         917   \n",
       "3                         20.195402                 208         962   \n",
       "4                         22.530864                 226         936   \n",
       "..                              ...                 ...         ...   \n",
       "145                       18.102041                 119         443   \n",
       "146                       24.209677                 139         766   \n",
       "147                       17.454545                 132         617   \n",
       "148                       24.862069                 115         394   \n",
       "149                       15.893939                 112         534   \n",
       "\n",
       "     syllable_count  personal_pronouns  average_word_length  \n",
       "0              1147                  0             6.423529  \n",
       "1              1543                  0             5.923234  \n",
       "2              3188                  1             6.552961  \n",
       "3              3097                  0             6.653386  \n",
       "4              3144                  1             6.504110  \n",
       "..              ...                ...                  ...  \n",
       "145            1393                  9             6.198422  \n",
       "146            2362                  2             6.035310  \n",
       "147            1910                  2             6.060764  \n",
       "148            1268                  0             6.669903  \n",
       "149            1668                  8             6.012393  \n",
       "\n",
       "[150 rows x 17 columns]"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "318f11b5d5929c1bb3530f7b0ec005ea5dc0b98ca838da92bfdb3650e5bc63c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
